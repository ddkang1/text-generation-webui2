version: "3.3"
services:
  text-generation-webui:
    build:
      context: .
      args:
        # specify which cuda version your card supports: https://developer.nvidia.com/cuda-gpus
        TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST}
        WEBUI_VERSION: ${WEBUI_VERSION}
    environment:
      # - CLI_ARGS=--extensions openai --n-gpu-layers 30 --listen --listen-host 0.0.0.0
      - CLI_ARGS=--listen --listen-host 0.0.0.0 --verbose
    env_file: .env
    ports:
      - "${HOST_PORT}:${CONTAINER_PORT}"
      - "${HOST_API_PORT}:${CONTAINER_API_PORT}"
      - "${HOST_API_STREAM_PORT}:${CONTAINER_API_STREAM_PORT}"
    stdin_open: true
    tty: true
    volumes:
      - ./characters:/app/characters
      - ./extensions:/app/extensions
      - ./loras:/app/loras
      - ~/models:/app/models
      - ./presets:/app/presets
      - ./prompts:/app/prompts
      - ./softprompts:/app/softprompts
      - ./training:/app/training
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]

  # chatgpt:
  #   image: 522185657747.dkr.ecr.us-west-2.amazonaws.com/chatbot-ui
  #   ports:
  #     - 3000:3000
  #   environment:
  #     - 'OPENAI_API_KEY=sk-'
  #     - 'OPENAI_API_HOST=http://api:${OPENEDAI_PORT}'

#aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 522185657747.dkr.ecr.us-west-2.amazonaws.com